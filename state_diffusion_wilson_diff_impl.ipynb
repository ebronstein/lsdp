{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8fd3e4e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a36a3146",
   "metadata": {},
   "source": [
    "import datetime\n",
    "import functools\n",
    "import os\n",
    "import sys\n",
    "from typing import Callable, Optional\n",
    "\n",
    "if \"PyTorch_VAE\" not in sys.path:\n",
    "    sys.path.append(\"PyTorch_VAE\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "from PyTorch_VAE import models\n",
    "from diffusion_policy.common.sampler import get_val_mask\n",
    "from diffusion_policy.dataset.pusht_image_dataset import PushTImageDataset"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b1be489f",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a8cb3fe",
   "metadata": {},
   "source": [
    "def plot_losses(train_losses, test_losses):\n",
    "    # Plot train and test losses.\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(train_losses, label=\"Train Loss\")\n",
    "    plt.plot(\n",
    "        np.linspace(0, len(train_losses), len(test_losses)),\n",
    "        test_losses,\n",
    "        label=\"Test Loss\",\n",
    "    )\n",
    "    # Remove outliers for better visualization\n",
    "    # plt.ylim(0, 0.01)\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "86488006",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0872279d",
   "metadata": {},
   "source": [
    "path = \"/nas/ucb/ebronstein/lsdp/diffusion_policy/data/pusht/pusht_cchi_v7_replay.zarr\"\n",
    "# path = \"/home/tsadja/data_diffusion/pusht/pusht_cchi_v7_replay.zarr\"\n",
    "# path = '/home/matteogu/ssd_data/data_diffusion/pusht/pusht_cchi_v7_replay.zarr'\n",
    "\n",
    "dataset = PushTImageDataset(path)\n",
    "full_dataset = torch.from_numpy(dataset.replay_buffer[\"img\"]).permute(0, 3, 1, 2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "478eb179",
   "metadata": {},
   "source": [
    "def normalize_pn1(x, min_val, max_val):\n",
    "    # Normalize to [0, 1]\n",
    "    nx = (x - min_val) / (max_val - min_val)\n",
    "    # Normalize to [-1, 1]\n",
    "    return nx * 2 - 1\n",
    "\n",
    "\n",
    "def denormalize_pn1(nx, min_val, max_val):\n",
    "    # Denormalize from [-1, 1]\n",
    "    x = (nx + 1) / 2\n",
    "    # Denormalize from [0, 1]\n",
    "    return x * (max_val - min_val) + min_val\n",
    "\n",
    "\n",
    "# Make the state normalizer.\n",
    "max_state = dataset.replay_buffer[\"state\"].max(axis=0)\n",
    "min_state = np.zeros_like(max_state)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2092758",
   "metadata": {},
   "source": [
    "class EpisodeDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset,\n",
    "        n_obs_history=1,\n",
    "        n_pred_horizon=1,\n",
    "        episode_idxs=None,\n",
    "        include_keys: Optional[list[str]] = None,\n",
    "        process_fns: Optional[dict[str, Callable]] = None,\n",
    "        device: str = \"cpu\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the dataset with the main dataset object that contains\n",
    "        the replay_buffer. Also, specify the lengths of observation history\n",
    "        and prediction horizon.\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.n_obs_history = n_obs_history\n",
    "        self.n_pred_horizon = n_pred_horizon\n",
    "        self.episode_idxs = list(episode_idxs)\n",
    "        self.include_keys = set(include_keys) if include_keys is not None else None\n",
    "        if not self.include_keys:\n",
    "            raise ValueError(\"At least one key must be included in the dataset.\")\n",
    "        self.process_fns = process_fns\n",
    "        self.device = device\n",
    "        self.prepare_data()\n",
    "\n",
    "    def prepare_data(self):\n",
    "        \"\"\"\n",
    "        Preprocess the episodes to create a flat list of samples.\n",
    "        Each sample is a tuple of dictionaries: (obs_history, pred_horizon).\n",
    "        \"\"\"\n",
    "        self.samples = []\n",
    "\n",
    "        if self.episode_idxs is None:\n",
    "            self.episode_idxs = range(self.dataset.replay_buffer.n_episodes)\n",
    "\n",
    "        for episode_idx in tqdm(self.episode_idxs, desc=\"Preparing data\"):\n",
    "            episode = self.dataset.replay_buffer.get_episode(episode_idx)\n",
    "\n",
    "            obs = {}\n",
    "\n",
    "            if self.include_keys is None or \"img\" in self.include_keys:\n",
    "                img = episode[\"img\"].transpose(0, 3, 1, 2)  # CHW format\n",
    "                if \"img\" in self.process_fns:\n",
    "                    img = self.process_fns[\"img\"](img)\n",
    "                obs[\"img\"] = torch.tensor(img, dtype=torch.float32).to(self.device)\n",
    "\n",
    "            if self.include_keys is None or \"action\" in self.include_keys:\n",
    "                action = episode[\"action\"]\n",
    "                if \"action\" in self.process_fns:\n",
    "                    action = self.process_fns[\"action\"](action)\n",
    "                obs[\"action\"] = torch.tensor(action, dtype=torch.float32).to(\n",
    "                    self.device\n",
    "                )\n",
    "\n",
    "            if self.include_keys is None or \"state\" in self.include_keys:\n",
    "                state = episode[\"state\"]\n",
    "                if \"state\" in self.process_fns:\n",
    "                    state = self.process_fns[\"state\"](state)\n",
    "                obs[\"state\"] = torch.tensor(state, dtype=torch.float32).to(self.device)\n",
    "\n",
    "            # Iterate through the episode to create samples with observation history and prediction horizon\n",
    "            n_obs = len(list(obs.values())[0])\n",
    "            for i in range(n_obs - self.n_obs_history - self.n_pred_horizon + 1):\n",
    "                obs_history = {}\n",
    "                pred_horizon = {}\n",
    "\n",
    "                for key, value in obs.items():\n",
    "                    obs_history[key] = value[i : i + self.n_obs_history]\n",
    "                    pred_horizon[key] = value[\n",
    "                        i\n",
    "                        + self.n_obs_history : i\n",
    "                        + self.n_obs_history\n",
    "                        + self.n_pred_horizon\n",
    "                    ]\n",
    "\n",
    "                self.samples.append((obs_history, pred_horizon))\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the total number of samples across all episodes.\n",
    "        \"\"\"\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Return the idx-th sample from the dataset.\n",
    "        \"\"\"\n",
    "        obs_history, pred_horizon = self.samples[idx]\n",
    "\n",
    "        # Convert data to PyTorch tensors and ensure the data type is correct\n",
    "        # for key, value in obs_history.items():\n",
    "        #     obs_history[key] = torch.tensor(value, dtype=torch.float32)\n",
    "        # for key, value in pred_horizon.items():\n",
    "        #     pred_horizon[key] = torch.tensor(value, dtype=torch.float32)\n",
    "\n",
    "        return obs_history, pred_horizon"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1b52b06b",
   "metadata": {},
   "source": [
    "# Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "10049f9f",
   "metadata": {},
   "source": [
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "\n",
    "def train(model, train_loader, optimizer, scheduler, obs_key: str = \"state\"):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for batch in tqdm(train_loader, total=len(train_loader)):\n",
    "        obs_history, pred_horizon = batch\n",
    "        obs = obs_history[obs_key].cuda()\n",
    "        loss = model.loss(obs)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        train_losses.append(loss.item())\n",
    "    return train_losses\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_loss(model, data_loader, obs_key: str = \"state\"):\n",
    "    model.eval()\n",
    "    total_loss, total = 0, 0\n",
    "    for batch in data_loader:\n",
    "        obs_history, pred_horizon = batch\n",
    "        obs = obs_history[obs_key].cuda()\n",
    "        loss = model.loss(obs)\n",
    "        num_data = obs.shape[0]\n",
    "        total_loss += loss.item() * num_data\n",
    "        total += num_data\n",
    "    avg_loss = total_loss / total\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def get_lr(step, total_steps, warmup_steps, use_cos_decay):\n",
    "    if step < warmup_steps:\n",
    "        mul = (step + 1) / warmup_steps\n",
    "        return mul\n",
    "    else:\n",
    "        if use_cos_decay:\n",
    "            progress = (step - warmup_steps) / (total_steps - warmup_steps)\n",
    "            return (1 + math.cos(math.pi * progress)) / 2\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "\n",
    "def train_epochs(model, train_loader, test_loader, train_args, obs_key: str = \"state\"):\n",
    "    epochs, lr = train_args[\"epochs\"], train_args[\"lr\"]\n",
    "    warmup_steps = train_args.get(\"warmup\", 0)\n",
    "    use_cos_decay = train_args.get(\"use_cos_decay\", False)\n",
    "    optimizer = optim.Adam(model.parameters(), lr)\n",
    "    total_steps = epochs * len(train_loader)\n",
    "    scheduler = optim.lr_scheduler.LambdaLR(\n",
    "        optimizer,\n",
    "        lr_lambda=lambda step: get_lr(step, total_steps, warmup_steps, use_cos_decay),\n",
    "    )\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = [eval_loss(model, test_loader, obs_key=obs_key)]\n",
    "    for epoch in tqdm(list(range(epochs))):\n",
    "        train_loss = train(model, train_loader, optimizer, scheduler, obs_key=obs_key)\n",
    "        train_losses.extend(train_loss)\n",
    "        test_loss = eval_loss(model, test_loader, obs_key=obs_key)\n",
    "        test_losses.append(test_loss)\n",
    "        print(\n",
    "            f\"Epoch {epoch}, Test loss {test_loss:.4f}, Train loss {np.mean(train_loss):.4f}\"\n",
    "        )\n",
    "\n",
    "    return np.array(train_losses), np.array(test_losses)\n",
    "\n",
    "\n",
    "class Diffusion:\n",
    "    def __init__(self, model, data_shape, encode_fn=None, decode_fn=None):\n",
    "        self.model = model\n",
    "        self.data_shape = data_shape\n",
    "        self.encode_fn = encode_fn\n",
    "        self.decode_fn = decode_fn\n",
    "\n",
    "    def _get_alpha_sigma(self, t):\n",
    "        return torch.cos(t * math.pi / 2), torch.sin(t * math.pi / 2)\n",
    "\n",
    "    def _expand(self, t):\n",
    "        for _ in range(len(self.data_shape)):\n",
    "            t = t[..., None]\n",
    "        return t\n",
    "\n",
    "    def _noise(self, x, eps=None, t=None):\n",
    "        if t is None:\n",
    "            t = torch.rand(x.shape[0], dtype=torch.float32, device=x.device)\n",
    "        if eps is None:\n",
    "            eps = torch.randn_like(x)\n",
    "        alpha_t, sigma_t = self._get_alpha_sigma(self._expand(t))\n",
    "        # print(\"t:\", t.shape)\n",
    "        # print(\"expand(t):\", self._expand(t).shape)\n",
    "        # print(\"alpha_t:\", alpha_t.shape)\n",
    "        # print(\"sigma_t:\", sigma_t.shape)\n",
    "        # print(\"x:\", x.shape)\n",
    "        # print(\"eps:\", eps.shape)\n",
    "        x_t = alpha_t * x + sigma_t * eps\n",
    "        return x_t, eps, t\n",
    "\n",
    "    def _x_hat(self, x_t, eps_hat, t):\n",
    "        alpha_t, sigma_t = self._get_alpha_sigma(self._expand(t))\n",
    "        return (x_t - sigma_t * eps_hat) / alpha_t\n",
    "\n",
    "    def loss(self, x, y=None):\n",
    "        if self.encode_fn is not None:\n",
    "            x = self.encode_fn(x)\n",
    "        x_t, eps, t = self._noise(x)\n",
    "        if y is not None:\n",
    "            eps_hat = self.model(x_t, y, t)\n",
    "        else:\n",
    "            eps_hat = self.model(x_t, t)\n",
    "        return torch.mean((eps_hat - eps) ** 2)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(\n",
    "        self,\n",
    "        n,\n",
    "        num_steps,\n",
    "        clip_denoised=False,\n",
    "        clip_noise=None,\n",
    "        model_fn=None,\n",
    "        cfg_val=None,\n",
    "    ):\n",
    "        model_fn = model_fn or self.model\n",
    "\n",
    "        ts = np.linspace(1 - 1e-4, 1e-4, num_steps + 1, dtype=np.float32)\n",
    "        x = torch.randn(n, *self.data_shape, dtype=torch.float32).cuda()\n",
    "        for i in range(num_steps):\n",
    "            t_cur = torch.full((n,), ts[i], dtype=torch.float32).cuda()\n",
    "            t_next = torch.full((n,), ts[i + 1], dtype=torch.float32).cuda()\n",
    "\n",
    "            alpha_cur, sigma_cur = self._get_alpha_sigma(self._expand(t_cur))\n",
    "            alpha_next, sigma_next = self._get_alpha_sigma(self._expand(t_next))\n",
    "            ddim_sigma = (sigma_next / sigma_cur) * torch.sqrt(\n",
    "                1 - alpha_cur**2 / alpha_next**2\n",
    "            )\n",
    "\n",
    "            if cfg_val is None:\n",
    "                eps_hat = model_fn(x, t_cur)\n",
    "            else:\n",
    "                eps_hat_cond = model_fn(x, t_cur)\n",
    "                eps_hat_uncond = model_fn(x, t_cur, dropout_cond=True)\n",
    "                eps_hat = eps_hat_uncond + cfg_val * (eps_hat_cond - eps_hat_uncond)\n",
    "\n",
    "            x_hat = self._x_hat(x, eps_hat, t_cur)\n",
    "            if clip_denoised:\n",
    "                x_hat = torch.clamp(x_hat, -1, 1)\n",
    "\n",
    "            noise = torch.randn_like(eps_hat)\n",
    "            if clip_noise:\n",
    "                noise = torch.clamp(noise, clip_noise[0], clip_noise[1])\n",
    "\n",
    "            x = (\n",
    "                alpha_next * x_hat\n",
    "                + torch.sqrt((sigma_next**2 - ddim_sigma**2).clamp(min=0)) * eps_hat\n",
    "                + ddim_sigma * noise\n",
    "            )\n",
    "        if self.decode_fn is not None:\n",
    "            x = self.decode_fn(x)\n",
    "        return x\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        if name in [\"train\", \"eval\", \"parameters\", \"state_dict\", \"load_state_dict\"]:\n",
    "            return getattr(self.model, name)\n",
    "        return self.__getattribute__(name)\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, n_hidden_layers, timestep_dim=1):\n",
    "        super().__init__()\n",
    "        self.timestep_dim = timestep_dim\n",
    "        prev_dim = input_dim + timestep_dim\n",
    "        net = []\n",
    "        dims = [hidden_dim] * n_hidden_layers + [input_dim]\n",
    "        for i, dim in enumerate(dims):\n",
    "            net.append(nn.Linear(prev_dim, dim))\n",
    "            if i < len(dims) - 1:\n",
    "                net.append(nn.ReLU())\n",
    "            prev_dim = dim\n",
    "        self.net = nn.Sequential(*net)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        \"\"\"Run a forward pass.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Data with shape [batch_size, n_history, input_dim].\n",
    "            t (torch.Tensor): Time embedding with shape [batch_size].\n",
    "        \"\"\"\n",
    "        flat_x = x.flatten(1)  # [batch_size, n_history * input_dim]\n",
    "        xt = torch.cat([flat_x, t[:, None]], dim=1)\n",
    "        out = self.net(xt)\n",
    "        return out.reshape(x.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f5b3cd99",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a4fae5d4",
   "metadata": {},
   "source": [
    "# Make train and val loaders\n",
    "val_mask = get_val_mask(dataset.replay_buffer.n_episodes, 0.1)\n",
    "val_idxs = np.where(val_mask)[0]\n",
    "train_idxs = np.where(~val_mask)[0]\n",
    "\n",
    "# Make the episode dataset and create a DataLoader.\n",
    "batch_size = 256\n",
    "n_obs_history = 5\n",
    "n_pred_horizon = 0\n",
    "\n",
    "state_normalizer = functools.partial(\n",
    "    normalize_pn1, min_val=min_state, max_val=max_state\n",
    ")\n",
    "process_fns = {\"state\": state_normalizer}\n",
    "include_keys = [\"state\"]\n",
    "\n",
    "train_episode_dataset = EpisodeDataset(\n",
    "    dataset,\n",
    "    n_obs_history=n_obs_history,\n",
    "    n_pred_horizon=n_pred_horizon,\n",
    "    episode_idxs=train_idxs,\n",
    "    include_keys=include_keys,\n",
    "    process_fns=process_fns,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "val_episode_dataset = EpisodeDataset(\n",
    "    dataset,\n",
    "    n_obs_history=n_obs_history,\n",
    "    n_pred_horizon=n_pred_horizon,\n",
    "    episode_idxs=val_idxs,\n",
    "    include_keys=include_keys,\n",
    "    process_fns=process_fns,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_episode_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_episode_dataset, batch_size=batch_size, shuffle=False\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c7e438f2",
   "metadata": {},
   "source": [
    "# Normalization sanity check\n",
    "# obs_history, pred_horizon = next(iter(train_loader))\n",
    "\n",
    "# for key, value in obs_history.items():\n",
    "#     print(key, value.shape)\n",
    "#     print(\"min:\", value.min(axis=0), \"max:\", value.max(axis=0))\n",
    "\n",
    "# for key, value in pred_horizon.items():\n",
    "#     print(key, value.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e6d891e7",
   "metadata": {},
   "source": [
    "# wandb_run = wandb.init(project='check_norms', name='first_run', reinit=True)\n",
    "wandb_run = None\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "STATE_DIM = 5\n",
    "input_dim = n_obs_history * STATE_DIM\n",
    "hidden_dim = 512\n",
    "n_hidden_layers = 4\n",
    "\n",
    "mlp = MLP(input_dim, hidden_dim, n_hidden_layers, timestep_dim=1).to(device)\n",
    "model = Diffusion(mlp, (n_obs_history, STATE_DIM))\n",
    "\n",
    "train_losses, test_losses = train_epochs(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    dict(epochs=100, lr=1e-3, warmup=100, use_cos_decay=True),\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cd540615",
   "metadata": {},
   "source": [
    "plot_losses(train_losses, test_losses)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "874b2152",
   "metadata": {},
   "source": [
    "# Save the model\n",
    "# save_dir = \"models/diffusion/pusht_mlp_5x512/2024-04-15\"\n",
    "save_dir = None\n",
    "if save_dir is not None:\n",
    "    os.makedirs(save_dir, exist_ok=False)\n",
    "    diffusion.save(os.path.join(save_dir, \"diffusion_model_final.pt\"))\n",
    "    np.save(os.path.join(save_dir, \"train_losses.npy\"), train_losses)\n",
    "    np.save(os.path.join(save_dir, \"test_losses.npy\"), test_losses)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c6c38a2d",
   "metadata": {},
   "source": [
    "## Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ae7f5b58",
   "metadata": {},
   "source": [
    "num_samples = 10000\n",
    "num_steps_list = [512]\n",
    "normalized_samples = []\n",
    "clip_noise = (-3, 3)\n",
    "for num_steps in num_steps_list:\n",
    "    normalized_samples.append(\n",
    "        model.sample(\n",
    "            num_samples, num_steps=num_steps, clip_denoised=True, clip_noise=clip_noise\n",
    "        )\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "    )\n",
    "normalized_samples = np.stack(normalized_samples, axis=0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "373453c9",
   "metadata": {},
   "source": [
    "# TODO: remove NaNs?\n",
    "for norm_samples_i in normalized_samples:\n",
    "    print(norm_samples_i.min(), norm_samples_i.max())\n",
    "    print(\n",
    "        norm_samples_i[~np.isnan(norm_samples_i)].min(),\n",
    "        norm_samples_i[~np.isnan(norm_samples_i)].max(),\n",
    "    )"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e874ce11",
   "metadata": {},
   "source": [
    "samples = denormalize_pn1(normalized_samples, min_state, max_state)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "611244fd",
   "metadata": {},
   "source": [
    "# TODO: remove NaNs?\n",
    "for samples_i in samples:\n",
    "    print(samples_i.min(), samples_i.max())\n",
    "    print(\n",
    "        samples_i[~np.isnan(samples_i)].min(),\n",
    "        samples_i[~np.isnan(samples_i)].max(),\n",
    "    )"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3c9f0912",
   "metadata": {},
   "source": [
    "# Plot histogram of each dimension of the samples\n",
    "for i, steps in enumerate(num_steps_list):\n",
    "    step_samples = samples[i]  # [num_samples, n_history, dim]\n",
    "    n_history = step_samples.shape[1]\n",
    "    dim = step_samples.shape[2]\n",
    "\n",
    "    fig, ax = plt.subplots(n_history, dim, figsize=(12, 12))\n",
    "\n",
    "    for i in range(n_history):\n",
    "        for j in range(dim):\n",
    "\n",
    "            ax[i, j].hist(\n",
    "                step_samples[:, i, j],\n",
    "                density=True,\n",
    "                bins=50,\n",
    "                color=\"blue\",\n",
    "                alpha=0.5,\n",
    "                # label=f\"samples {i}\",\n",
    "            )\n",
    "            ax[i, j].hist(\n",
    "                dataset.replay_buffer[\"state\"][:, j],\n",
    "                density=True,\n",
    "                bins=50,\n",
    "                color=\"green\",\n",
    "                alpha=0.5,\n",
    "                # label=f\"replay {i}\",\n",
    "            )\n",
    "            ax[i, j].set_title(f\"History {i}, Dim {j}\")\n",
    "            # ax[i, j].legend()\n",
    "\n",
    "    fig.suptitle(f\"{steps} steps\")\n",
    "    plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "44e2a18a",
   "metadata": {},
   "source": [
    "diff_states = []\n",
    "for obs_history, pred_horizon in train_loader:\n",
    "    state = obs_history[\"state\"].detach().cpu().numpy()\n",
    "    diff_states.append(np.diff(state, axis=1))\n",
    "\n",
    "diff_states = np.concatenate(diff_states, axis=0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4be46082",
   "metadata": {},
   "source": [
    "diff_samples = np.diff(samples, axis=2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c41a3864",
   "metadata": {},
   "source": [
    "nan_exists = np.isnan(diff_samples).any(axis=(2, 3))\n",
    "diff_samples_no_nan = diff_samples[:, ~nan_exists[0]]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8af39a02",
   "metadata": {},
   "source": [
    "# Plot histogram of each dimension of the samples\n",
    "for i, steps in enumerate(num_steps_list):\n",
    "    step_diff_samples = diff_samples_no_nan[i]  # [num_samples, n_history, dim]\n",
    "    n_history = step_diff_samples.shape[1]\n",
    "    dim = step_diff_samples.shape[2]\n",
    "\n",
    "    fig, axs = plt.subplots(n_history, dim, figsize=(12, 12))\n",
    "\n",
    "    for i in range(n_history):\n",
    "        for j in range(dim):\n",
    "            ax = axs[i, j]\n",
    "            ax.hist(\n",
    "                step_diff_samples[:, i, j],\n",
    "                density=True,\n",
    "                bins=50,\n",
    "                color=\"blue\",\n",
    "                alpha=0.5,\n",
    "                # label=f\"samples {i}\",\n",
    "            )\n",
    "\n",
    "            ax.set_title(f\"History {i}, Dim {j}\")\n",
    "            # ax.legend()\n",
    "\n",
    "    fig.suptitle(f\"{steps} steps\")\n",
    "    plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d029b180",
   "metadata": {},
   "source": [
    "# Plot histogram of each dimension of the samples\n",
    "for i, steps in enumerate(num_steps_list):\n",
    "    step_diff_samples = diff_samples_no_nan[i]  # [num_samples, n_history, dim]\n",
    "    n_history = step_diff_samples.shape[1]\n",
    "    dim = step_diff_samples.shape[2]\n",
    "\n",
    "    fig, axs = plt.subplots(n_history, dim, figsize=(12, 12))\n",
    "\n",
    "    for i in range(n_history):\n",
    "        for j in range(dim):\n",
    "            ax = axs[i, j]\n",
    "            ax.hist(\n",
    "                diff_states[:, i, j],\n",
    "                density=True,\n",
    "                bins=50,\n",
    "                color=\"green\",\n",
    "                alpha=0.5,\n",
    "                # label=f\"replay {i}\",\n",
    "            )\n",
    "\n",
    "            # ax.set_title(f\"History {i}, Dim {j}\")\n",
    "            # ax.legend()\n",
    "\n",
    "    fig.suptitle(f\"{steps} steps\")\n",
    "    plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "961848fd",
   "metadata": {},
   "source": [
    "### Debug sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf88f6b",
   "metadata": {},
   "source": [
    "for p in diffusion.model.parameters():\n",
    "    # print(p)\n",
    "    if torch.isnan(p).any():\n",
    "        print(\"NaNs in the parameters.\")\n",
    "    else:\n",
    "        param_norm = p.norm(2)\n",
    "        print(param_norm)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
