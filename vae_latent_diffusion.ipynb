{
 "cells": [
  {
   "cell_type": "code",
   "id": "a36a3146",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T17:19:28.478897Z",
     "start_time": "2024-04-30T17:19:27.402466Z"
    }
   },
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import functools\n",
    "import math\n",
    "import time\n",
    "from typing import Optional\n",
    "\n",
    "if \"PyTorch_VAE\" not in sys.path:\n",
    "    sys.path.append(\"PyTorch_VAE\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "\n",
    "from PyTorch_VAE import models\n",
    "from diffusion_policy.common.pytorch_util import compute_conv_output_shape\n",
    "from diffusion_policy.dataset.pusht_image_dataset import PushTImageDataset\n",
    "\n",
    "from lsdp_utils.VanillaVAE import VanillaVAE\n",
    "from lsdp_utils.utils import bcolors\n",
    "\n",
    "from types import SimpleNamespace\n"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T17:19:42.529430Z",
     "start_time": "2024-04-30T17:19:42.456035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "cfg = SimpleNamespace(dataset_path='/home/matteogu/ssd_data/data_diffusion/pusht/pusht_cchi_v7_replay.zarr',\n",
    "                      # vae_model_path='/home/matteogu/Desktop/prj_deepul/repo_online/lsdp/models/pusht_vae/vae_32_20240403.pt',\n",
    "                      vae_save_dir='/home/matteogu/ssd_data/diffusion_models/models/diffusion/vae/',\n",
    "\n",
    "                      latent_dim=512,\n",
    "                      hidden_dims=[32, 64, 128, 256, 512],\n",
    "                      batch_size=128,\n",
    "                      down_dims=[1024, 2048],  # 512, 1024,\n",
    "                      train_split=0.8,\n",
    "                      lr=1e-3,  # optimization params\n",
    "                      kld_weight=1e-7,\n",
    "                      epochs=100,\n",
    "                      device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "                      )\n"
   ],
   "id": "5a32e25092cfe0ce",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "79ec2083",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T17:19:45.950189Z",
     "start_time": "2024-04-30T17:19:44.255785Z"
    }
   },
   "source": [
    "\n",
    "dataset = PushTImageDataset(cfg.dataset_path)\n",
    "full_dataset = torch.from_numpy(dataset.replay_buffer[\"img\"]).permute(0, 3, 1, 2)\n",
    "\n",
    "str_hidden = str(cfg.hidden_dims)[1:-1].replace(\", \", \"_\")\n",
    "name = (f'pusht_vae_klw_{cfg.kld_weight:.2e}_ldim_{cfg.latent_dim}_'\n",
    "        f'bs_{cfg.batch_size}_epochs_{cfg.epochs}_lr_{cfg.lr}_kld_{cfg.kld_weight:.2f}_hdim_{str_hidden}')\n",
    "save_dir = f'{cfg.vae_save_dir}{name}'\n",
    "os.makedirs(save_dir)\n",
    "print(f\"{bcolors.OKGREEN} ---------------------- {bcolors.ENDC}\")\n",
    "print(f\"{bcolors.OKGREEN}   {name}   {bcolors.ENDC}\")\n",
    "print(f\"{bcolors.OKGREEN} ---------------------- {bcolors.ENDC}\")\n",
    "\n",
    "\n",
    "def normalize(data):\n",
    "    data /= 255.0\n",
    "    data = 2 * data - 1\n",
    "    return data\n",
    "\n",
    "\n",
    "def unnormalize(data):\n",
    "    data = (data + 1) / 2\n",
    "    data *= 255\n",
    "    return data\n",
    "\n",
    "\n",
    "full_dataset = normalize(full_dataset)\n",
    "N, C, H, W = full_dataset.shape\n",
    "\n",
    "train_size = int(cfg.train_split * N)\n",
    "val_size = N - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    full_dataset, [train_size, val_size]\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=cfg.batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset.to(cfg.device), batch_size=cfg.batch_size, shuffle=True)\n"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ce31b32f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T17:20:05.445992Z",
     "start_time": "2024-04-30T17:20:04.488264Z"
    }
   },
   "source": "val_dataset.dataset.to(cfg.device)",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "b37d3cca66a27cfe",
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "3271409a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T16:27:28.838623Z",
     "start_time": "2024-04-30T16:27:28.836074Z"
    }
   },
   "source": "from vae.pusht_vae import VanillaVAE  # same VAE of lsdp_utils/VanillaVAE ",
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "e6d2fe57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T16:27:31.889914Z",
     "start_time": "2024-04-30T16:27:31.158275Z"
    }
   },
   "source": "",
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "5ba95ff2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T16:27:43.760729Z",
     "start_time": "2024-04-30T16:27:43.042487Z"
    }
   },
   "source": "",
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "aa109673",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T16:38:39.362213Z",
     "start_time": "2024-04-30T16:38:09.439123Z"
    }
   },
   "source": [
    "epochs = 20\n",
    "train_losses, val_losses = [], []\n",
    "train_recons_losses, train_kld_losses = [], []\n",
    "val_recons_losses, val_kld_losses = [], []\n",
    "\n",
    "kld_weight = 1e-7\n",
    "\n",
    "for epoch in trange(epochs):\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "    for i, x in enumerate(train_loader):\n",
    "        x = x.to(device)\n",
    "        result = model(x)\n",
    "        loss = model.loss_function(*result, M_N=kld_weight)  # [\"loss\"]\n",
    "         # {'loss': loss, 'Reconstruction_Loss':recons_loss.detach(), 'KLD':-kld_loss.detach()}\n",
    "        total_train_loss += loss['loss'].item()\n",
    "        \n",
    "        train_losses.append(loss['loss'].item())\n",
    "        train_recons_losses.append(loss['Reconstruction_Loss'].item())\n",
    "        train_kld_losses.append(loss['KLD'].item())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss['loss'].backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f\"Train loss: {total_train_loss / len(train_loader):.4f}\")\n",
    "\n",
    "    total_val_loss = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, x in enumerate(val_loader):\n",
    "            x = x.to(device)\n",
    "            result = model(x)\n",
    "            loss = model.loss_function(*result, M_N=kld_weight)\n",
    "            \n",
    "            val_recons_losses.append(loss['Reconstruction_Loss'].item())\n",
    "            val_kld_losses.append(loss['KLD'].item())\n",
    "        \n",
    "        \n",
    "            total_val_loss += loss[\"loss\"].item()\n",
    "    val_losses.append(total_val_loss / len(val_loader))\n",
    "    print(f\"Validation loss: {val_losses[-1]:.4f}\")\n"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127ed7c4",
   "metadata": {},
   "source": [
    "def show_reconstructions(model: VanillaVAE, val_loader: torch.utils.data.DataLoader, save_fig: bool = False):\n",
    "    val_data = next(iter(val_loader))\n",
    "    num_samples = 5\n",
    "    val_data = val_data.to(device)\n",
    "    result = model(val_data)\n",
    "    recon = result[0]\n",
    "    recon = unnormalize(recon)\n",
    "    val_data = unnormalize(val_data)\n",
    "\n",
    "    fig, ax = plt.subplots(2, num_samples, figsize=(num_samples*2, 6))\n",
    "    # fig.set_size_inches(10, 10)\n",
    "    for ii in range(num_samples):\n",
    "        ax[0, ii].imshow(\n",
    "            val_data[ii].permute(1, 2, 0).cpu().detach().numpy().astype(np.uint8)\n",
    "        )\n",
    "        ax[1, ii].imshow(\n",
    "            recon[ii].permute(1, 2, 0).cpu().detach().numpy().astype(np.uint8)\n",
    "        )\n",
    "        ax[0, ii].axis('off')\n",
    "        ax[1, ii].axis('off')\n",
    "        \n",
    "    # plt.suptitle(\"Reconstructions\")\n",
    "    ax[0, 0].set_title('Ground Truth')\n",
    "    ax[1, 0].set_title('Reconstruction')\n",
    "    plt.tight_layout()\n",
    "    if save_fig: plt.savefig(f'figs/pusht_vae/reconstructions_{latent_dim}.png')\n",
    "    plt.show()\n",
    "    \n",
    "show_reconstructions(model, val_loader, save_fig=True)"
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plt.plot(train_losses)\n",
    "# plt.plot(val_losses)\n",
    "def plot_losses(train_losses, test_losses):\n",
    "    # Plot train and test losses.\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(train_losses, label=\"Train Loss\")\n",
    "    plt.semilogy(\n",
    "        np.linspace(0, len(train_losses), len(test_losses)),\n",
    "        test_losses,\n",
    "        label=\"Test Loss\",\n",
    "    )\n",
    "    # Remove outliers for better visualization\n",
    "    # plt.ylim(0, 0.01)\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.title(f'[Latent {latent_dim}] Final Test loss: {test_losses[-1]:.4f}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plot_losses(train_losses, val_losses)"
   ],
   "id": "183cac383a831761",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3773f4dd2178d008",
   "metadata": {},
   "source": [
    "with open(f'{save_dir}/losses/losses_{latent_dim}_{now}.npy', 'rb') as f:\n",
    "    train_losses_l = np.load(f)\n",
    "    val_losses_l = np.load(f)\n"
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Plots for the report",
   "id": "bdd3a73e5f870099"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os \n",
    "loss_path = 'models/pusht_vae/losses/'\n",
    "exps = os.listdir(loss_path)\n",
    "exps.sort()\n",
    "plt.figure(figsize=(12, 6))\n",
    "for exp in exps:\n",
    "    with open(f'{loss_path}{exp}', 'rb') as f:\n",
    "        _train_losses_ = np.load(f)\n",
    "        _val_losses = np.load(f)\n",
    "    \n",
    "    _latent_dim = int(exp.split('_')[1])\n",
    "    plt.semilogy(_train_losses_, label=f\"[{_latent_dim}] Train Loss\")    \n",
    "    plt.semilogy(\n",
    "        np.linspace(0, len(_train_losses_), len(_val_losses)),\n",
    "        _val_losses,\n",
    "        label=f\"[{_latent_dim}] Test Loss, final_value: {_val_losses[-1]:.4f}\",\n",
    "    )\n",
    "    # Remove outliers for better visualization\n",
    "    # plt.ylim(0, 0.01)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(f'Test loss vs Latent Dimension')\n",
    "plt.tight_layout()\n",
    "plt.savefig('Loss_vs_latent.png')\n",
    "plt.show()"
   ],
   "id": "1c734d4f3f852974",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "837db8f3",
   "metadata": {},
   "source": [
    "latent_dim = 32\n",
    "# Load the VAE\n",
    "model = VanillaVAE(in_channels=3, in_height=H, in_width=W, latent_dim=latent_dim).to(device)\n",
    "save_dir = \"models/pusht_vae\"\n",
    "model.load_state_dict(torch.load(os.path.join(save_dir, \"vae_32_20240403.pt\")))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09a58717",
   "metadata": {},
   "source": [
    "# Encode the full dataset\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    mu, log_var = model.encode(full_dataset.to(device))\n",
    "    mu = mu.cpu().detach().numpy()\n",
    "    log_var = log_var.cpu().detach().numpy()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61dccab4",
   "metadata": {},
   "source": [
    "mu.shape, log_var.shape"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sqllm",
   "language": "python",
   "name": "sqllm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
