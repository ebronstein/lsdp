{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cfg = SimpleNamespace(dataset_path='/home/matteogu/ssd_data/data_diffusion/pusht/pusht_cchi_v7_replay.zarr',\n",
    "                      # vae_model_path='/home/matteogu/Desktop/prj_deepul/repo_online/lsdp/models/pusht_vae/vae_32_20240403.pt',\n",
    "                      vae_save_dir='/home/matteogu/ssd_data/diffusion_models/models/vae/',\n",
    "\n",
    "                      kld_weight=1e-7,\n",
    "                      latent_dim=128,\n",
    "                      hidden_dims=[32, 64, 128, 256, 512],\n",
    "\n",
    "                      train_split=0.8,\n",
    "\n",
    "                      batch_size=512,\n",
    "                      lr=5e-4,  # optimization params\n",
    "\n",
    "                      epochs=100,) \n"
   ],
   "id": "9f8b75d631b55660",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import collections\n",
    "import copy\n",
    "import datetime\n",
    "import functools\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from typing import Callable, Optional\n",
    "\n",
    "if \"PyTorch_VAE\" not in sys.path:\n",
    "    sys.path.append(\"PyTorch_VAE\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "import wandb\n",
    "from diffusion_policy.common.pytorch_util import compute_conv_output_shape\n",
    "from diffusion_policy.common.sampler import get_val_mask\n",
    "from diffusion_policy.dataset.pusht_image_dataset import PushTImageDataset\n",
    "from diffusion_policy.model.diffusion import conditional_unet1d\n",
    "from ema import EMAHelper\n",
    "\n",
    "# Custom imports\n",
    "from PyTorch_VAE import models\n",
    "from lsdp_utils.Diffusion import Diffusion\n",
    "from lsdp_utils.VanillaVAE import VanillaVAE\n",
    "from lsdp_utils.EpisodeDataset import EpisodeDataset, EpisodeDataloaders\n",
    "from lsdp_utils.utils import plot_losses, plot_samples\n",
    "\n",
    "# model trained with the mlp to convert latents into states\n",
    "# pusht_unet1d_img_1024_2048_edim_256obs_0_pred_4_bs_64_lr_0.001_e_300/2024-04-30_12-22-07"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from types import SimpleNamespace\n",
    "cfg = SimpleNamespace(dataset_path='/home/matteogu/ssd_data/data_diffusion/pusht/pusht_cchi_v7_replay.zarr',\n",
    "                      # vae_model_path='/nas/ucb/ebronstein/lsdp/models/pusht_vae/vae_32_20240403.pt',\n",
    "                      vae_model_path='/home/matteogu/Desktop/prj_deepul/repo_online/lsdp/models/pusht_vae/vae_32_20240403.pt',\n",
    "                      save_dir='/home/matteogu/ssd_data/diffusion_models/models/diffusion/',\n",
    "                      batch_size=4096,  # 3.8 Giga for state, better 512 for latents\n",
    "                      n_obs_history=8,\n",
    "                      n_pred_horizon=8,\n",
    "                      down_dims=[256, 512, 1024],\n",
    "                      diffusion_step_embed_dim=128,  # in the original paper was 256\n",
    "                      lr=3e-4,  # optimization params\n",
    "                      epochs=200,\n",
    "                      device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "                      obs_key=\"img\",\n",
    "                      )"
   ],
   "id": "67d4fb6ad0778370",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e24a1130674c9f3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "cfg_dict"
   ],
   "id": "d0c3f6e305fa986a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "list_of_files = glob.glob(f'{cfg.save_dir}*')\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "print(latest_file)\n",
    "list_of_files = glob.glob(f'{latest_file}/*')\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "print(latest_file)\n"
   ],
   "id": "e30e2c7f318bc9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#\n",
    "\n",
    "load_dir2 = f'{cfg.save_dir}pusht_unet1d_img_256_512_1024_obs_8_pred_8/2024-04-29_18-59-25'\n",
    "# # load_dir = f'{cfg.save_dir}pusht_unet1d_state_256_512_1024_obs_8_pred_8/2024-04-29_19-20-23'\n",
    "# load_dir1 = f'{cfg.save_dir}pusht_unet1d_img_256_512_1024_2048_edim_128obs_8_pred_8_bs_4096_lr_3e-05_e_200/2024-04-29_19-43-11'\n",
    "\n",
    "load_dir = f'{latest_file}'\n",
    "# os.listdir(load_dir)\n",
    "# diffusion.load(os.path.join(load_dir, \"diffusion_model_final.pt\"))\n",
    "train_losses = np.load(os.path.join(load_dir, \"train_losses.npy\"))\n",
    "test_losses = np.load(os.path.join(load_dir, \"test_losses.npy\"))\n",
    "plot_losses(train_losses, test_losses)\n",
    "\n",
    "# \n",
    "# train_losses2 = np.load(os.path.join(load_dir2, \"train_losses.npy\"))\n",
    "# test_losses2 = np.load(os.path.join(load_dir2, \"test_losses.npy\"))\n",
    "# \n",
    "# plot_losses(train_losses1, test_losses1)\n",
    "# plot_losses(train_losses2, test_losses2)"
   ],
   "id": "641ea11aa84d6799",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "706fb21ebdd80778",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d1ada95c98450b21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "assert cfg.obs_key == \"img\" or cfg.obs_key == \"state\"\n",
    "\n",
    "\n",
    "dataset = PushTImageDataset(cfg.dataset_path)\n",
    "full_dataset = torch.from_numpy(dataset.replay_buffer[\"img\"]).permute(0, 3, 1, 2)\n",
    "N, C, H, W = full_dataset.shape\n",
    "\n",
    "# Make the state normalizer.\n",
    "max_state = dataset.replay_buffer[\"state\"].max(axis=0)\n",
    "min_state = dataset.replay_buffer[\"state\"].min(axis=0)\n",
    "\n",
    "if cfg.obs_key == \"img\":\n",
    "    # Load VAE.\n",
    "    latent_dim = 32\n",
    "    vae_model = VanillaVAE(\n",
    "        in_channels=3, in_height=H, in_width=W, latent_dim=latent_dim\n",
    "    ).to(cfg.device)\n",
    "    vae_model.load_state_dict(torch.load(cfg.vae_model_path))\n",
    "    cfg.STATE_DIM = latent_dim\n",
    "\n",
    "    def get_latent(x, vae_model, device):\n",
    "        x = x / 255.0\n",
    "        x = 2 * x - 1\n",
    "        return vae_model.encode(torch.from_numpy(x).to(device))[0].detach()\n",
    "\n",
    "    normalize_encoder_input = functools.partial(\n",
    "        get_latent, vae_model=vae_model, device=cfg.device\n",
    "    )\n",
    "else:\n",
    "    cfg.STATE_DIM = 5\n",
    "    normalize_encoder_input = None\n",
    "\n",
    "# Make train and val loaders\n",
    "val_mask = get_val_mask(dataset.replay_buffer.n_episodes, 0.1)\n",
    "val_idxs = np.where(val_mask)[0]\n",
    "train_idxs = np.where(~val_mask)[0]\n",
    "\n",
    "state_normalizer = functools.partial(\n",
    "    normalize_pn1, min_val=min_state, max_val=max_state\n",
    ")\n",
    "\n",
    "process_fns = {\"state\": state_normalizer, \"img\": normalize_encoder_input}\n",
    "\n",
    "print(\"Making datasets and dataloaders.\")\n",
    "train_loader, val_loader = EpisodeDataloaders(dataset=dataset,\n",
    "                                              episode_train_idxs=train_idxs,\n",
    "                                              episode_val_idxs=val_idxs,\n",
    "                                              include_keys=[cfg.obs_key],  # one key only\n",
    "                                              process_fns=process_fns,\n",
    "                                              cfg=cfg)  # configuration params\n",
    "\n",
    "global_cond_dim = cfg.STATE_DIM * cfg.n_obs_history\n",
    "\n",
    "diff_model = conditional_unet1d.ConditionalUnet1D(\n",
    "    input_dim=cfg.STATE_DIM,\n",
    "    down_dims=cfg.down_dims,\n",
    "    diffusion_step_embed_dim=cfg.diffusion_step_embed_dim,\n",
    "    global_cond_dim=global_cond_dim,\n",
    ").to(cfg.device)\n",
    "\n",
    "optim_kwargs = dict(lr=cfg.lr)\n",
    "diffusion = Diffusion(\n",
    "    train_data=train_loader,\n",
    "    test_data=val_loader,\n",
    "    model=diff_model,\n",
    "    n_epochs=cfg.epochs,\n",
    "    optim_kwargs=optim_kwargs,\n",
    "    device=cfg.device,\n",
    ")\n"
   ],
   "id": "82ea347137d25bda",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "load_dir = f'{cfg.save_dir}pusht_unet1d_img_256_512_1024_obs_8_pred_8'\n",
    "diffusion.load(os.path.join(load_dir, \"diffusion_model_final.pt\"))\n",
    "train_losses = np.load(os.path.join(load_dir, \"train_losses.npy\"))\n",
    "test_losses = np.load(os.path.join(load_dir, \"test_losses.npy\"))"
   ],
   "id": "3bc156507f5e07ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "load_dir = \"models/diffusion/pusht-1dconv_latent_128_256_512_1024-obs_8-pred_8/2024-04-28_00-43-07\"\n",
    "\n",
    "if load_dir is not None:\n",
    "    diffusion.load(os.path.join(load_dir, \"diffusion_model_final.pt\"))\n",
    "    train_losses = np.load(os.path.join(load_dir, \"train_losses.npy\"))\n",
    "    test_losses = np.load(os.path.join(load_dir, \"test_losses.npy\"))"
   ],
   "id": "36ceb439a0a0c057",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sqllm",
   "language": "python",
   "name": "sqllm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
