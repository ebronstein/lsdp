{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8fd3e4e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a36a3146",
   "metadata": {},
   "source": [
    "import collections\n",
    "import datetime\n",
    "import functools\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "from typing import Callable, Optional\n",
    "\n",
    "if \"PyTorch_VAE\" not in sys.path:\n",
    "    sys.path.append(\"PyTorch_VAE\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "from PyTorch_VAE import models\n",
    "from diffusion_policy.common.sampler import get_val_mask\n",
    "from diffusion_policy.common.pytorch_util import compute_conv_output_shape\n",
    "from diffusion_policy.dataset.pusht_image_dataset import PushTImageDataset"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b1be489f",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a8cb3fe",
   "metadata": {},
   "source": [
    "def plot_losses(train_losses, test_losses):\n",
    "    # Plot train and test losses.\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(train_losses, label=\"Train Loss\")\n",
    "    plt.plot(\n",
    "        np.linspace(0, len(train_losses), len(test_losses)),\n",
    "        test_losses,\n",
    "        label=\"Test Loss\",\n",
    "    )\n",
    "    # Remove outliers for better visualization\n",
    "    # plt.ylim(0, 0.01)\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "86488006",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0872279d",
   "metadata": {},
   "source": [
    "path = \"/nas/ucb/ebronstein/lsdp/diffusion_policy/data/pusht/pusht_cchi_v7_replay.zarr\"\n",
    "# path = \"/home/tsadja/data_diffusion/pusht/pusht_cchi_v7_replay.zarr\"\n",
    "# path = '/home/matteogu/ssd_data/data_diffusion/pusht/pusht_cchi_v7_replay.zarr'\n",
    "\n",
    "dataset = PushTImageDataset(path)\n",
    "full_dataset = torch.from_numpy(dataset.replay_buffer[\"img\"]).permute(0, 3, 1, 2)\n",
    "N, C, H, W = full_dataset.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "478eb179",
   "metadata": {},
   "source": [
    "def normalize_pn1(x, min_val, max_val):\n",
    "    # Normalize to [0, 1]\n",
    "    nx = (x - min_val) / (max_val - min_val)\n",
    "\n",
    "    # Normalize to [-1, 1]\n",
    "    return nx * 2 - 1\n",
    "\n",
    "\n",
    "def denormalize_pn1(nx, min_val, max_val):\n",
    "    # Denormalize from [-1, 1]\n",
    "    x = (nx + 1) / 2\n",
    "\n",
    "    # Denormalize from [0, 1]\n",
    "    return x * (max_val - min_val) + min_val\n",
    "\n",
    "\n",
    "# Make the state normalizer.\n",
    "max_state = dataset.replay_buffer[\"state\"].max(axis=0)\n",
    "\n",
    "# TODO: does this make a difference?\n",
    "# min_state = np.zeros_like(max_state)\n",
    "min_state = dataset.replay_buffer[\"state\"].min(axis=0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c52a3865",
   "metadata": {},
   "source": [
    "min_state, max_state"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2092758",
   "metadata": {},
   "source": [
    "class EpisodeDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset,\n",
    "        n_obs_history=1,\n",
    "        n_pred_horizon=1,\n",
    "        episode_idxs=None,\n",
    "        include_keys: Optional[list[str]] = None,\n",
    "        process_fns: Optional[dict[str, Callable]] = None,\n",
    "        device: str = \"cpu\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the dataset with the main dataset object that contains\n",
    "        the replay_buffer. Also, specify the lengths of observation history\n",
    "        and prediction horizon.\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.n_obs_history = n_obs_history\n",
    "        self.n_pred_horizon = n_pred_horizon\n",
    "        self.episode_idxs = list(episode_idxs)\n",
    "        self.include_keys = set(include_keys) if include_keys is not None else None\n",
    "        if not self.include_keys:\n",
    "            raise ValueError(\"At least one key must be included in the dataset.\")\n",
    "        self.process_fns = process_fns\n",
    "        self.device = device\n",
    "        self.prepare_data()\n",
    "\n",
    "    def prepare_data(self):\n",
    "        \"\"\"\n",
    "        Preprocess the episodes to create a flat list of samples.\n",
    "        Each sample is a tuple of dictionaries: (obs_history, pred_horizon).\n",
    "        \"\"\"\n",
    "        self.samples = []\n",
    "\n",
    "        if self.episode_idxs is None:\n",
    "            self.episode_idxs = range(self.dataset.replay_buffer.n_episodes)\n",
    "\n",
    "        for episode_idx in tqdm(self.episode_idxs, desc=\"Preparing data\"):\n",
    "            episode = self.dataset.replay_buffer.get_episode(episode_idx)\n",
    "\n",
    "            obs = {}\n",
    "\n",
    "            if self.include_keys is None or \"img\" in self.include_keys:\n",
    "                img = episode[\"img\"].transpose(0, 3, 1, 2)  # CHW format\n",
    "                if \"img\" in self.process_fns:\n",
    "                    img = self.process_fns[\"img\"](img)\n",
    "                obs[\"img\"] = torch.tensor(img, dtype=torch.float32).to(self.device)\n",
    "\n",
    "            if self.include_keys is None or \"action\" in self.include_keys:\n",
    "                action = episode[\"action\"]\n",
    "                if \"action\" in self.process_fns:\n",
    "                    action = self.process_fns[\"action\"](action)\n",
    "                obs[\"action\"] = torch.tensor(action, dtype=torch.float32).to(\n",
    "                    self.device\n",
    "                )\n",
    "\n",
    "            if self.include_keys is None or \"state\" in self.include_keys:\n",
    "                state = episode[\"state\"]\n",
    "                if \"state\" in self.process_fns:\n",
    "                    state = self.process_fns[\"state\"](state)\n",
    "                obs[\"state\"] = torch.tensor(state, dtype=torch.float32).to(self.device)\n",
    "\n",
    "            # Iterate through the episode to create samples with observation history and prediction horizon\n",
    "            n_obs = len(list(obs.values())[0])\n",
    "            for i in range(n_obs - self.n_obs_history - self.n_pred_horizon + 1):\n",
    "                obs_history = {}\n",
    "                pred_horizon = {}\n",
    "\n",
    "                for key, value in obs.items():\n",
    "                    obs_history[key] = value[i : i + self.n_obs_history]\n",
    "                    pred_horizon[key] = value[\n",
    "                        i\n",
    "                        + self.n_obs_history : i\n",
    "                        + self.n_obs_history\n",
    "                        + self.n_pred_horizon\n",
    "                    ]\n",
    "\n",
    "                self.samples.append((obs_history, pred_horizon))\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the total number of samples across all episodes.\n",
    "        \"\"\"\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Return the idx-th sample from the dataset.\n",
    "        \"\"\"\n",
    "        obs_history, pred_horizon = self.samples[idx]\n",
    "\n",
    "        # Convert data to PyTorch tensors and ensure the data type is correct\n",
    "        # for key, value in obs_history.items():\n",
    "        #     obs_history[key] = torch.tensor(value, dtype=torch.float32)\n",
    "        # for key, value in pred_horizon.items():\n",
    "        #     pred_horizon[key] = torch.tensor(value, dtype=torch.float32)\n",
    "\n",
    "        return obs_history, pred_horizon"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1b52b06b",
   "metadata": {},
   "source": [
    "# Diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9793f0a5",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb0df932",
   "metadata": {},
   "source": [
    "class VanillaVAE(models.VanillaVAE):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        in_height: int,\n",
    "        in_width: int,\n",
    "        latent_dim: int,\n",
    "        hidden_dims: Optional[list] = None,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        models.BaseVAE.__init__(self)\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        modules = []\n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [32, 64, 128, 256, 512]\n",
    "\n",
    "        # Build Encoder\n",
    "        kernel_size = 3\n",
    "        stride = 2\n",
    "        padding = 1\n",
    "        dilation = 1\n",
    "        for h_dim in hidden_dims:\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(\n",
    "                        in_channels,\n",
    "                        out_channels=h_dim,\n",
    "                        kernel_size=kernel_size,\n",
    "                        stride=stride,\n",
    "                        padding=padding,\n",
    "                        dilation=dilation,\n",
    "                    ),\n",
    "                    nn.BatchNorm2d(h_dim),\n",
    "                    nn.LeakyReLU(),\n",
    "                )\n",
    "            )\n",
    "            in_channels = h_dim\n",
    "\n",
    "        self.conv_out_shape = compute_conv_output_shape(\n",
    "            H=in_height,\n",
    "            W=in_width,\n",
    "            padding=padding,\n",
    "            stride=stride,\n",
    "            kernel_size=kernel_size,\n",
    "            dilation=dilation,\n",
    "            num_layers=len(hidden_dims),\n",
    "            last_hidden_dim=hidden_dims[-1],\n",
    "        )\n",
    "        conv_out_size = np.prod(self.conv_out_shape)\n",
    "\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "        self.fc_mu = nn.Linear(conv_out_size, latent_dim)\n",
    "        self.fc_var = nn.Linear(conv_out_size, latent_dim)\n",
    "\n",
    "        # Build Decoder\n",
    "        modules = []\n",
    "\n",
    "        self.decoder_input = nn.Linear(latent_dim, conv_out_size)\n",
    "\n",
    "        hidden_dims.reverse()\n",
    "\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose2d(\n",
    "                        hidden_dims[i],\n",
    "                        hidden_dims[i + 1],\n",
    "                        kernel_size=3,\n",
    "                        stride=2,\n",
    "                        padding=1,\n",
    "                        output_padding=1,\n",
    "                    ),\n",
    "                    nn.BatchNorm2d(hidden_dims[i + 1]),\n",
    "                    nn.LeakyReLU(),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "\n",
    "        self.final_layer = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                hidden_dims[-1],\n",
    "                hidden_dims[-1],\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                output_padding=1,\n",
    "            ),\n",
    "            nn.BatchNorm2d(hidden_dims[-1]),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(hidden_dims[-1], out_channels=3, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def decode(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Maps the given latent codes\n",
    "        onto the image space.\n",
    "        :param z: (Tensor) [B x D]\n",
    "        :return: (Tensor) [B x C x H x W]\n",
    "        \"\"\"\n",
    "        result = self.decoder_input(z)\n",
    "        result = result.view(-1, *self.conv_out_shape)\n",
    "        result = self.decoder(result)\n",
    "        result = self.final_layer(result)\n",
    "        return result\n",
    "\n",
    "\n",
    "class DiffusionMLP(nn.Module):\n",
    "    def __init__(self, in_dim: int, out_dim: int, hidden_dims: list[int]):\n",
    "        super(DiffusionMLP, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(in_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            in_dim = hidden_dim\n",
    "        layers.append(nn.Linear(in_dim, out_dim))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        \"\"\"Run a forward pass.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Data with shape [batch_size, n_history, input_dim].\n",
    "            t (torch.Tensor): Time embedding with shape [batch_size].\n",
    "        \"\"\"\n",
    "        # print(\"x:\", x.shape)\n",
    "        flat_x = x.flatten(1)  # [batch_size, n_history * input_dim]\n",
    "        # print(\"flat_x:\", flat_x.shape)\n",
    "        # print(\"t:\", t.shape)\n",
    "        t = t.reshape(-1, 1)\n",
    "        # print(\"t:\", t.shape)\n",
    "        xt = torch.cat([flat_x, t], dim=1)\n",
    "        # print(\"xt:\", xt.shape)\n",
    "        out = self.net(xt)\n",
    "        # print(\"out:\", out.shape)\n",
    "        out = out.reshape(x.shape)\n",
    "        # print(\"out:\", out.shape)\n",
    "        return out"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0804a1c7",
   "metadata": {},
   "source": [
    "## Train/eval impl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "865c4cd1",
   "metadata": {},
   "source": [
    "from ema import EMAHelper\n",
    "\n",
    "def warmup_cosine_decay_scheduler(optimizer, warmup_steps, total_steps):\n",
    "    \"\"\"\n",
    "    Creates a scheduler with warmup followed by cosine decay.\n",
    "\n",
    "    Args:\n",
    "        optimizer: Optimizer linked to the model parameters.\n",
    "        warmup_steps: Number of steps for the warmup phase.\n",
    "        total_steps: Total number of steps in the training.\n",
    "    \"\"\"\n",
    "\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < warmup_steps:\n",
    "            # Linear warmup\n",
    "            return float(current_step) / float(max(1, warmup_steps))\n",
    "        # Cosine decay\n",
    "        progress = float(current_step - warmup_steps) / float(\n",
    "            max(1, total_steps - warmup_steps)\n",
    "        )\n",
    "        return 0.5 * (1.0 + np.cos(np.pi * progress))\n",
    "\n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "\n",
    "def dropout_classes(y, null_class, dropout_prob=0.1):\n",
    "    \"\"\"Randomly dropout classes with a given probability.\"\"\"\n",
    "    dropout_mask = torch.rand(y.shape) < dropout_prob\n",
    "    y[dropout_mask] = null_class\n",
    "    return y\n",
    "\n",
    "\n",
    "class Diffusion(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_data=None,\n",
    "        test_data=None,\n",
    "        model=None,\n",
    "        batch_size=1024,\n",
    "        n_epochs=100,\n",
    "        n_warmup_steps=100,\n",
    "        has_labels=False,\n",
    "        obs_normalizer=None,\n",
    "        optim_kwargs: dict = None,\n",
    "        device: str = \"cuda\",\n",
    "        use_ema_helper=False,\n",
    "    ):\n",
    "        if has_labels:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "        self.n_epochs = n_epochs\n",
    "        self.has_labels = has_labels\n",
    "        self.device = device\n",
    "\n",
    "        self.obs_normalizer = (\n",
    "            obs_normalizer if obs_normalizer is not None else lambda x: x\n",
    "        )\n",
    "\n",
    "        # Data loaders\n",
    "        if isinstance(train_data, torch.utils.data.DataLoader):\n",
    "            assert isinstance(test_data, torch.utils.data.DataLoader)\n",
    "            self.train_loader = train_data\n",
    "            self.test_loader = test_data\n",
    "            train_data_shape = None\n",
    "        elif train_data is not None:\n",
    "            assert test_data is not None\n",
    "            train_data_shape = train_data.shape\n",
    "            self.train_loader, self.test_loader = self.create_loaders(\n",
    "                train_data, test_data, batch_size\n",
    "            )\n",
    "        else:\n",
    "            self.train_loader = None\n",
    "            self.test_loader = None\n",
    "\n",
    "        if model is None:\n",
    "            assert train_data_shape is not None and len(train_data_shape) == 2\n",
    "            input_dim = train_data_shape[1]\n",
    "            self.model = DiffusionMLP(input_dim, input_dim)\n",
    "        else:\n",
    "            self.model = model\n",
    "        self.model = self.model.to(device)\n",
    "\n",
    "        def model_with_labels(x, labels, t, **kwargs):\n",
    "            return self.model(x, labels, t, **kwargs)\n",
    "\n",
    "        def model_without_labels(x, labels, t):\n",
    "            return self.model(x, t)\n",
    "\n",
    "        if has_labels:\n",
    "            self.model_fn = model_with_labels\n",
    "        else:\n",
    "            self.model_fn = model_without_labels\n",
    "\n",
    "        # Optimizer\n",
    "        optim_kwargs = optim_kwargs or {}\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), **optim_kwargs)\n",
    "\n",
    "        # LR scheduler\n",
    "        if self.train_loader is not None:\n",
    "            n_iters_per_epoch = len(self.train_loader)\n",
    "            n_iters = n_epochs * n_iters_per_epoch\n",
    "            self.scheduler = warmup_cosine_decay_scheduler(\n",
    "                self.optimizer, n_warmup_steps, n_iters\n",
    "            )\n",
    "        else:\n",
    "            self.scheduler = None\n",
    "\n",
    "        self.use_ema_helper = use_ema_helper\n",
    "        if self.use_ema_helper:\n",
    "            self.ema_helper = EMAHelper(model=copy.deepcopy(self.model), power=3 / 4)\n",
    "\n",
    "    def save(self, path):\n",
    "        torch.save(self.model.state_dict(), path)\n",
    "\n",
    "    def load(self, path):\n",
    "        self.model.load_state_dict(torch.load(path))\n",
    "\n",
    "    def create_loaders(self, train_data, test_data, batch_size):\n",
    "        train_data = torch.tensor(train_data, dtype=torch.float32)\n",
    "        test_data = torch.tensor(test_data, dtype=torch.float32)\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_data, batch_size=batch_size, shuffle=True\n",
    "        )\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            test_data, batch_size=batch_size, shuffle=False\n",
    "        )\n",
    "        return train_loader, test_loader\n",
    "\n",
    "    def get_alpha(self, t):\n",
    "        return torch.cos(np.pi / 2 * t).to(self.device)\n",
    "\n",
    "    def get_sigma(self, t):\n",
    "        return torch.sin(np.pi / 2 * t).to(self.device)\n",
    "\n",
    "    def compute_loss(self, x, labels=None):\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        # Step 1: Sample diffusion timestep uniformly in [0, 1]\n",
    "        t = torch.rand(batch_size, device=self.device)  # [batch_size]\n",
    "\n",
    "        # Step 2: Compute noise-strength\n",
    "        alpha_t = self.get_alpha(t)\n",
    "        sigma_t = self.get_sigma(t)\n",
    "\n",
    "        # Step 3: Apply forward process\n",
    "        epsilon = torch.randn_like(x, device=self.device)\n",
    "        exp_shape = [batch_size] + [1] * (len(x.shape) - 1)\n",
    "        alpha_t = alpha_t.view(exp_shape)\n",
    "        sigma_t = sigma_t.view(exp_shape)\n",
    "        # Print shapes\n",
    "        # print(\"x:\", x.shape)\n",
    "        # print(\"alpha_t:\", alpha_t.shape)\n",
    "        # print(\"sigma_t:\", sigma_t.shape)\n",
    "        # print(\"epsilon:\", epsilon.shape)\n",
    "        x_t = alpha_t * x + sigma_t * epsilon  # x.shape\n",
    "\n",
    "        # Step 4: Estimate epsilon\n",
    "        eps_hat = self.model_fn(x_t, labels, t)\n",
    "        # print(\"eps_hat:\", eps_hat.shape)\n",
    "\n",
    "        # Step 5: Optimize the loss\n",
    "        loss = (epsilon - eps_hat).pow(2).mean()\n",
    "        return loss\n",
    "\n",
    "    def eval(self, test_loader, obs_key: str = \"state\"):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x in test_loader:\n",
    "                if self.has_labels:\n",
    "                    raise NotImplementedError()\n",
    "                    x, labels = x\n",
    "                    labels = labels.to(self.device)\n",
    "                else:\n",
    "                    labels = None\n",
    "                obs_history, pred_horizon = x\n",
    "                obs = obs_history[obs_key].to(self.device)\n",
    "                obs = self.obs_normalizer(obs)\n",
    "\n",
    "                loss = self.compute_loss(obs, labels)\n",
    "                total_loss += loss.item() * obs.shape[0]\n",
    "\n",
    "        return total_loss / len(test_loader.dataset)\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        log_freq=100,\n",
    "        save_freq: int = 10,\n",
    "        obs_key: str = \"state\",\n",
    "        process_labels_fn=None,\n",
    "        save_dir=None,\n",
    "        wandb_run=None,\n",
    "    ):\n",
    "        if wandb_run is not None:\n",
    "            log_freq = None\n",
    "        if save_dir is not None:\n",
    "            # Get the current timestamp and save it as a new directory.\n",
    "            timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "            save_dir = os.path.join(save_dir, timestamp)\n",
    "            os.makedirs(save_dir)\n",
    "\n",
    "        train_losses = []\n",
    "        test_losses = [self.eval(self.test_loader, obs_key=obs_key)]\n",
    "\n",
    "        iter = 0\n",
    "        for epoch in range(self.n_epochs):\n",
    "            if wandb_run is not None:\n",
    "                wandb_run.log({\"epoch\": epoch + 1})\n",
    "            epoch_train_losses = []\n",
    "            # grad_norms = []\n",
    "            self.model.train()\n",
    "\n",
    "            for x in self.train_loader:\n",
    "                if self.has_labels:\n",
    "                    raise NotImplementedError()\n",
    "                    x, labels = x\n",
    "                    labels = labels.to(self.device)\n",
    "                    if process_labels_fn is not None:\n",
    "                        labels = process_labels_fn(labels)\n",
    "                else:\n",
    "                    labels = None\n",
    "\n",
    "                obs_history, pred_horizon = x\n",
    "                obs = obs_history[obs_key].to(self.device)\n",
    "                # print(\"obs:\", obs.shape)\n",
    "                obs = self.obs_normalizer(obs)\n",
    "                # print(\"obs:\", obs.shape)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss = self.compute_loss(obs, labels)\n",
    "                loss.backward()\n",
    "\n",
    "                # Compute the norm of gradients\n",
    "                total_norm = 0\n",
    "                for p in self.model.parameters():\n",
    "                    param_norm = p.grad.data.norm(2)\n",
    "                    total_norm += param_norm.item() ** 2\n",
    "                total_norm = total_norm**0.5\n",
    "                if wandb_run is not None:\n",
    "                    wandb_run.log({\"grad_norm\": total_norm})\n",
    "                    wandb_run.log({\"batch_loss\": loss.item()})\n",
    "                # grad_norms.append(total_norm)\n",
    "\n",
    "                self.optimizer.step()\n",
    "                self.scheduler.step()\n",
    "\n",
    "                if self.use_ema_helper:\n",
    "                    self.ema_helper.step(self.model)\n",
    "\n",
    "                epoch_train_losses.append(loss.item())\n",
    "\n",
    "                if log_freq is not None and iter % log_freq == 0:\n",
    "                    print(f\"Epoch {epoch+1}, iter {iter}, Loss: {loss.item()}\")\n",
    "\n",
    "                iter += 1\n",
    "\n",
    "            train_losses.extend(epoch_train_losses)\n",
    "            test_losses.append(self.eval(self.test_loader, obs_key=obs_key))\n",
    "\n",
    "            if save_dir is not None and epoch % save_freq == 0:\n",
    "                self.save(os.path.join(save_dir, f\"diffusion_model_epoch_{epoch}.pt\"))\n",
    "\n",
    "        if save_dir is not None:\n",
    "            self.save(os.path.join(save_dir, \"diffusion_model_final.pt\"))\n",
    "            np.save(os.path.join(save_dir, \"train_losses.npy\"), train_losses)\n",
    "            np.save(os.path.join(save_dir, \"test_losses.npy\"), test_losses)\n",
    "\n",
    "        return train_losses, test_losses\n",
    "\n",
    "\n",
    "def ddpm_update(\n",
    "    x,\n",
    "    eps_hat,\n",
    "    alpha_t,\n",
    "    alpha_tm1,\n",
    "    sigma_t,\n",
    "    sigma_tm1,\n",
    "    clip=None,\n",
    "    clip_noise=None,\n",
    "    device: str = \"cuda\",\n",
    "):\n",
    "    # assert not torch.isnan(eps_hat).any()\n",
    "    # assert not torch.isnan(sigma_t).any()\n",
    "    # assert alpha_t.abs().min() > 1e-6\n",
    "    if torch.isnan(eps_hat).any():\n",
    "        print(\"nan eps_hat\")\n",
    "    if torch.isnan(sigma_t).any():\n",
    "        print(\"nan sigma_t\")\n",
    "    if alpha_t.abs().min() < 1e-6:\n",
    "        print(\"alpha_t is too small\")\n",
    "    eta_t = sigma_tm1 / sigma_t * torch.sqrt(1 - alpha_t.pow(2) / alpha_tm1.pow(2))\n",
    "    # assert not torch.isnan(eta_t).any()\n",
    "    if torch.isnan(eta_t).any():\n",
    "        print(\"nan eta_t\")\n",
    "    x_tm1_mean = (x - sigma_t * eps_hat) / alpha_t\n",
    "    # assert not torch.isnan(x_tm1_mean).any()\n",
    "    if torch.isnan(x_tm1_mean).any():\n",
    "        print(\"nan x_tm1_mean\")\n",
    "    if clip is not None:\n",
    "        min, max = clip\n",
    "        x_tm1_mean = torch.clamp(x_tm1_mean, min, max)\n",
    "    update_term = alpha_tm1 * x_tm1_mean\n",
    "    # assert not torch.isnan(update_term).any()\n",
    "    if torch.isnan(update_term).any():\n",
    "        print(\"nan update_term\")\n",
    "    noise_term = (\n",
    "        torch.sqrt(torch.clamp(sigma_tm1.pow(2) - eta_t.pow(2), min=0)) * eps_hat\n",
    "    )\n",
    "    # assert not torch.isnan(noise_term).any()\n",
    "    if torch.isnan(noise_term).any():\n",
    "        print(\"nan noise_term\")\n",
    "    random_noise = torch.randn_like(x, device=device)\n",
    "    if clip_noise:\n",
    "        random_noise = torch.clamp(random_noise, clip_noise[0], clip_noise[1])\n",
    "    random_noise *= eta_t\n",
    "    x_tm1 = update_term + noise_term + random_noise\n",
    "    return x_tm1\n",
    "\n",
    "\n",
    "def sample(\n",
    "    model,\n",
    "    num_samples,\n",
    "    return_steps,\n",
    "    data_shape,\n",
    "    labels=None,\n",
    "    clip=None,\n",
    "    clip_noise=None,\n",
    "    cfg_w=None,\n",
    "    null_class=None,\n",
    "    device: str = \"cuda\",\n",
    "):\n",
    "    model.model.eval()\n",
    "    if not isinstance(data_shape, (list, tuple)):\n",
    "        data_shape = (data_shape,)\n",
    "    x_shape = (num_samples,) + tuple(data_shape)\n",
    "    exp_shape = [num_samples] + [1] * len(data_shape)\n",
    "    samples = []  # [num_labels, len(return_steps), num_samples, *data_shape]\n",
    "\n",
    "    if cfg_w is not None:\n",
    "        assert labels is not None\n",
    "        assert null_class is not None\n",
    "        with torch.no_grad():\n",
    "            null_class = torch.tensor(\n",
    "                null_class, dtype=torch.int32, device=device\n",
    "            ).expand(num_samples)\n",
    "\n",
    "    if labels is None:\n",
    "        labels = [None]\n",
    "        model_kwargs = {}\n",
    "    else:\n",
    "        model_kwargs = {\"training\": False}\n",
    "\n",
    "    for label in labels:\n",
    "        label_samples = []\n",
    "        with torch.no_grad():\n",
    "            if label is not None:\n",
    "                label = torch.tensor(label, dtype=torch.int32, device=device)\n",
    "                label = label.expand(num_samples)\n",
    "            for num_steps in return_steps:\n",
    "                ts = np.linspace(1 - 1e-4, 1e-4, num_steps + 1)\n",
    "\n",
    "                x = torch.randn(x_shape, device=device)\n",
    "                for i in range(num_steps):\n",
    "                    t = torch.tensor([ts[i]], dtype=torch.float32, device=device)\n",
    "                    tm1 = torch.tensor([ts[i + 1]], dtype=torch.float32, device=device)\n",
    "\n",
    "                    alpha_t = model.get_alpha(t).expand(exp_shape)\n",
    "                    alpha_tm1 = model.get_alpha(tm1).expand(exp_shape)\n",
    "                    sigma_t = model.get_sigma(t).expand(exp_shape)\n",
    "                    sigma_tm1 = model.get_sigma(tm1).expand(exp_shape)\n",
    "\n",
    "                    # assert not torch.isnan(x).any(), f\"step: {i}\"\n",
    "                    if torch.isnan(x).any():\n",
    "                        print(\"nan x at step = \", i)\n",
    "                    eps_hat = model.model_fn(\n",
    "                        x, label, t.expand(num_samples), **model_kwargs\n",
    "                    )\n",
    "                    # assert not torch.isnan(eps_hat).any(), f\"step: [{i}/{num_steps}], t: {t}\"\n",
    "                    if torch.isnan(eps_hat).any():\n",
    "                        print(\"nan eps_hat step = \", i)\n",
    "                        breakpoint()\n",
    "                    if cfg_w is not None:\n",
    "                        eps_hat_null = model.model_fn(\n",
    "                            x, null_class, t.expand(num_samples), **model_kwargs\n",
    "                        )\n",
    "                        eps_hat = eps_hat_null + cfg_w * (eps_hat - eps_hat_null)\n",
    "\n",
    "                    x = ddpm_update(\n",
    "                        x,\n",
    "                        eps_hat,\n",
    "                        alpha_t,\n",
    "                        alpha_tm1,\n",
    "                        sigma_t,\n",
    "                        sigma_tm1,\n",
    "                        clip=clip,\n",
    "                        clip_noise=clip_noise,\n",
    "                    )\n",
    "\n",
    "                label_samples.append(x.cpu().detach().numpy())\n",
    "            samples.append(label_samples)\n",
    "\n",
    "    # Squeeze out the label and return_steps dimensions if there's only.\n",
    "    samples = np.array(samples)\n",
    "    if len(labels) == 1:\n",
    "        samples = samples.squeeze(0)\n",
    "    return samples\n",
    "\n",
    "\n",
    "def _get_alpha_sigma(t):\n",
    "    return torch.cos(t * math.pi / 2), torch.sin(t * math.pi / 2)\n",
    "\n",
    "\n",
    "def _expand(t, data_shape):\n",
    "    for _ in range(len(data_shape)):\n",
    "        t = t[..., None]\n",
    "    return t\n",
    "\n",
    "\n",
    "def _x_hat(x_t, eps_hat, t, data_shape):\n",
    "    alpha_t, sigma_t = _get_alpha_sigma(_expand(t, data_shape))\n",
    "    return (x_t - sigma_t * eps_hat) / alpha_t\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample_pieter(\n",
    "    model_fn, n, num_steps, data_shape, clip_denoised=False, cfg_val=None\n",
    "):\n",
    "\n",
    "    ts = np.linspace(1 - 1e-4, 1e-4, num_steps + 1, dtype=np.float32)\n",
    "    x = torch.randn(n, *data_shape, dtype=torch.float32).cuda()\n",
    "    for i in range(num_steps):\n",
    "        t_cur = torch.full((n,), ts[i], dtype=torch.float32).cuda()\n",
    "        t_next = torch.full((n,), ts[i + 1], dtype=torch.float32).cuda()\n",
    "\n",
    "        alpha_cur, sigma_cur = _get_alpha_sigma(_expand(t_cur, data_shape))\n",
    "        alpha_next, sigma_next = _get_alpha_sigma(_expand(t_next, data_shape))\n",
    "        ddim_sigma = (sigma_next / sigma_cur) * torch.sqrt(\n",
    "            1 - alpha_cur**2 / alpha_next**2\n",
    "        )\n",
    "\n",
    "        if cfg_val is None:\n",
    "            eps_hat = model_fn(x, None, t_cur)  # Labels are None.\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "            # eps_hat_cond = model_fn(x, t_cur)\n",
    "            # eps_hat_uncond = model_fn(x, t_cur, dropout_cond=True)\n",
    "            # eps_hat = eps_hat_uncond + cfg_val * (eps_hat_cond - eps_hat_uncond)\n",
    "\n",
    "        x_hat = _x_hat(x, eps_hat, t_cur, data_shape)\n",
    "        if clip_denoised:\n",
    "            x_hat = torch.clamp(x_hat, -1, 1)\n",
    "        x = (\n",
    "            alpha_next * x_hat\n",
    "            + torch.sqrt((sigma_next**2 - ddim_sigma**2).clamp(min=0)) * eps_hat\n",
    "            + ddim_sigma * torch.randn_like(eps_hat)\n",
    "        )\n",
    "    # if self.decode_fn is not None:\n",
    "    #     x = self.decode_fn(x)\n",
    "    return x"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f5b3cd99",
   "metadata": {},
   "source": [
    "## Make data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4fae5d4",
   "metadata": {},
   "source": [
    "# Make train and val loaders\n",
    "val_mask = get_val_mask(dataset.replay_buffer.n_episodes, 0.1)\n",
    "val_idxs = np.where(val_mask)[0]\n",
    "train_idxs = np.where(~val_mask)[0]\n",
    "# train_idxs = [0]\n",
    "# val_idxs = [1]\n",
    "\n",
    "# Make the episode dataset and create a DataLoader.\n",
    "batch_size = 256\n",
    "n_obs_history = 8\n",
    "n_pred_horizon = 0\n",
    "\n",
    "\n",
    "def get_normalized_T_xy(state):\n",
    "    \"\"\"Get the normalized x, y coordinates of the T.\n",
    "\n",
    "    Args:\n",
    "        state (np.ndarray): State with shape (n, 5).\n",
    "    \"\"\"\n",
    "    xy = state[:, 2:4]\n",
    "    return normalize_pn1(xy, min_val=min_state[2:4], max_val=max_state[2:4])\n",
    "\n",
    "\n",
    "device = \"cuda\"\n",
    "obs_key = \"img\"\n",
    "\n",
    "if obs_key == \"state\":\n",
    "    state_normalizer = functools.partial(\n",
    "        normalize_pn1, min_val=min_state, max_val=max_state\n",
    "    )\n",
    "    process_fns = {\"state\": state_normalizer}\n",
    "    # process_fns = {\"state\": get_normalized_T_xy}\n",
    "\n",
    "    include_keys = [\"state\"]\n",
    "elif obs_key == \"img\":\n",
    "    latent_dim = 32\n",
    "    vae_model_path = \"models/pusht_vae/vae_32_20240403.pt\"\n",
    "\n",
    "    vae_model = VanillaVAE(\n",
    "        in_channels=C,\n",
    "        in_height=H,\n",
    "        in_width=W,\n",
    "        latent_dim=latent_dim,\n",
    "        hidden_dims=[32, 64, 128, 256, 512],\n",
    "    ).to(device)\n",
    "    vae_model.load_state_dict(torch.load(vae_model_path))\n",
    "    STATE_DIM = latent_dim\n",
    "\n",
    "    def get_latent(x, vae_model, device):\n",
    "        x = x / 255.0\n",
    "        x = 2.0 * x - 1.0\n",
    "        return vae_model.encode(torch.from_numpy(x).to(device))[0].detach()\n",
    "\n",
    "    normalize_encoder_input = functools.partial(\n",
    "        get_latent, vae_model=vae_model, device=device\n",
    "    )\n",
    "    process_fns = {\"img\": normalize_encoder_input}\n",
    "\n",
    "include_keys = [obs_key]\n",
    "train_episode_dataset = EpisodeDataset(\n",
    "    dataset,\n",
    "    n_obs_history=n_obs_history,\n",
    "    n_pred_horizon=n_pred_horizon,\n",
    "    episode_idxs=train_idxs,\n",
    "    include_keys=include_keys,\n",
    "    process_fns=process_fns,\n",
    "    device=device,\n",
    ")\n",
    "val_episode_dataset = EpisodeDataset(\n",
    "    dataset,\n",
    "    n_obs_history=n_obs_history,\n",
    "    n_pred_horizon=n_pred_horizon,\n",
    "    episode_idxs=val_idxs,\n",
    "    include_keys=include_keys,\n",
    "    process_fns=process_fns,\n",
    "    device=device,\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_episode_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_episode_dataset, batch_size=batch_size, shuffle=False\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa124535",
   "metadata": {},
   "source": [
    "if obs_key == \"img\":\n",
    "    # Compute the mean and standard deviation of the VAE latents on the training set.\n",
    "    train_latents = []\n",
    "    for x in train_loader:\n",
    "        obs_history, pred_horizon = x\n",
    "        latent = obs_history[obs_key].to(device)  # [B, obs_history, latent_dim]\n",
    "        train_latents.append(latent.flatten(0, 1).cpu().numpy())\n",
    "\n",
    "    train_latents = np.concatenate(train_latents, axis=0)\n",
    "    latent_min = train_latents.min(axis=0)\n",
    "    latent_max = train_latents.max(axis=0)\n",
    "\n",
    "    obs_normalizer = functools.partial(\n",
    "        normalize_pn1,\n",
    "        min_val=torch.tensor(latent_min, dtype=torch.float32, device=device),\n",
    "        max_val=torch.tensor(latent_max, dtype=torch.float32, device=device),\n",
    "    )\n",
    "else:\n",
    "    obs_normalizer = None"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e438f2",
   "metadata": {},
   "source": [
    "# Normalization sanity check\n",
    "obs_history_min = collections.defaultdict(lambda: np.inf)\n",
    "obs_history_max = collections.defaultdict(lambda: -np.inf)\n",
    "\n",
    "for obs_history, pred_horizon in train_loader:\n",
    "\n",
    "    for key, value in obs_history.items():\n",
    "        # print(key, value.shape)\n",
    "        # print(\"min:\", value.min(axis=0), \"max:\", value.max(axis=0))\n",
    "\n",
    "        # Normalize.\n",
    "        if obs_normalizer is not None:\n",
    "            value = obs_normalizer(value)\n",
    "\n",
    "        obs_history_min[key] = np.minimum(\n",
    "            obs_history_min[key], value.min(axis=0).values.cpu().numpy()\n",
    "        )\n",
    "        obs_history_max[key] = np.maximum(\n",
    "            obs_history_max[key], value.max(axis=0).values.cpu().numpy()\n",
    "        )\n",
    "\n",
    "    # for key, value in pred_horizon.items():\n",
    "    # print(key, value.shape)\n",
    "    # print(\"min:\", value.min(axis=0), \"max:\", value.max(axis=0))\n",
    "\n",
    "obs_history_min, obs_history_max"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ae264e04",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d891e7",
   "metadata": {},
   "source": [
    "from diffusion_policy.model.diffusion import conditional_unet1d\n",
    "from importlib import reload\n",
    "\n",
    "conditional_unet1d = reload(conditional_unet1d)\n",
    "\n",
    "# wandb_run = wandb.init(project='check_norms', name='first_run', reinit=True)\n",
    "wandb_run = None\n",
    "\n",
    "if obs_key == \"state\":\n",
    "    STATE_DIM = 5\n",
    "elif obs_key == \"img\":\n",
    "    STATE_DIM = 32\n",
    "else:\n",
    "    raise NotImplementedError()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# input_dim + 1 because the time step is concatenated to the state.\n",
    "# input_dim = n_obs_history * STATE_DIM + 1\n",
    "# hidden_dims = [256] * 4\n",
    "# diff_model = DiffusionMLP(input_dim, input_dim - 1, hidden_dims).to(device)\n",
    "\n",
    "if n_obs_history == 1:\n",
    "    down_dims = [128, 256]\n",
    "elif n_obs_history == 4:\n",
    "    down_dims = [128, 256, 512]\n",
    "elif n_obs_history == 8:\n",
    "    down_dims = [128, 256, 512, 1024]\n",
    "else:\n",
    "    raise NotImplementedError()\n",
    "\n",
    "diff_model = conditional_unet1d.ConditionalUnet1D(\n",
    "    input_dim=STATE_DIM, down_dims=down_dims\n",
    ").to(device)\n",
    "\n",
    "optim_kwargs = dict(lr=1e-3)\n",
    "diffusion = Diffusion(\n",
    "    train_data=train_loader,\n",
    "    test_data=val_loader,\n",
    "    obs_normalizer=obs_normalizer,\n",
    "    model=diff_model,\n",
    "    n_epochs=30,\n",
    "    optim_kwargs=optim_kwargs,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# load_dir = \"models/diffusion/pusht_1dconv_128_256_512_1024/2024-04-25_23-29-40/2024-04-25_23-29-40\"\n",
    "# load_dir = \"models/diffusion/pusht_1dconv_latent_128_256_512_1024/2024-04-26_00-45-03\"\n",
    "load_dir = None\n",
    "if load_dir is not None:\n",
    "    diffusion.load(os.path.join(load_dir, \"diffusion_model_final.pt\"))\n",
    "else:\n",
    "    train_losses, test_losses = diffusion.train(obs_key=obs_key, wandb_run=wandb_run)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd540615",
   "metadata": {},
   "source": [
    "load_dir = \"models/diffusion/pusht_unet1d_img_128_256_512_1024_edim_256_obs_8_pred_8_bs_256_lr_0.0003_e_250_ema_norm_latent_uniform/2024-05-06_01-09-27\"\n",
    "if load_dir is not None:\n",
    "    train_losses = np.load(os.path.join(load_dir, \"train_losses.npy\"))\n",
    "    test_losses = np.load(os.path.join(load_dir, \"test_losses.npy\"))\n",
    "\n",
    "num_steps = max(len(train_losses), len(test_losses))\n",
    "plot_losses(train_losses[:num_steps], test_losses[:num_steps])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874b2152",
   "metadata": {},
   "source": [
    "# Save the model\n",
    "# save_dir = \"models/diffusion/pusht_mlp_5x512/2024-04-15\"\n",
    "save_dir = None\n",
    "if save_dir is not None:\n",
    "    os.makedirs(save_dir, exist_ok=False)\n",
    "    diffusion.save(os.path.join(save_dir, \"diffusion_model_final.pt\"))\n",
    "    np.save(os.path.join(save_dir, \"train_losses.npy\"), train_losses)\n",
    "    np.save(os.path.join(save_dir, \"test_losses.npy\"), test_losses)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c6c38a2d",
   "metadata": {},
   "source": [
    "## Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7f5b58",
   "metadata": {},
   "source": [
    "return_steps = [512]\n",
    "num_samples = 1000\n",
    "normalized_samples = sample(\n",
    "    diffusion,\n",
    "    num_samples=num_samples,\n",
    "    return_steps=return_steps,\n",
    "    data_shape=(n_obs_history, STATE_DIM),\n",
    "    clip=None,\n",
    "    clip_noise=(-3, 3),\n",
    "    device=device,\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6dfd1f",
   "metadata": {},
   "source": [
    "normalized_samples.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99338cd",
   "metadata": {},
   "source": [
    "if obs_key == \"img\":\n",
    "    # Load VAE\n",
    "    vae_model_path = \"/nas/ucb/ebronstein/lsdp/models/pusht_vae/vae_32_20240403.pt\"\n",
    "    latent_dim = 32\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    vae_model = VanillaVAE(\n",
    "        in_channels=3, in_height=H, in_width=W, latent_dim=latent_dim\n",
    "    ).to(device)\n",
    "    vae_model.load_state_dict(torch.load(vae_model_path))\n",
    "\n",
    "    # Decode using VAE.\n",
    "\n",
    "    batch_size = 8\n",
    "    vae_model.to(device)\n",
    "\n",
    "    # Decode the samples in batches\n",
    "    decoded_normalized_samples = []\n",
    "    num_batches = 10  # num_samples // batch_size\n",
    "    reshape_batch_shape = (\n",
    "        [batch_size, n_obs_history]\n",
    "        if n_obs_history != 0\n",
    "        else [batch_size, n_pred_horizon]\n",
    "    )\n",
    "\n",
    "    mask = ((normalized_samples >= -1) & (normalized_samples <= 1)).all(axis=(-2, -1))\n",
    "    # Range: [-1, 1] (for real now)\n",
    "    in_range_normalized_samples = normalized_samples[mask][None]\n",
    "\n",
    "    for i in trange(0, num_batches, batch_size):\n",
    "        # Range: [-1, 1]\n",
    "        normalized_batch_samples = in_range_normalized_samples[\n",
    "            0, i : i + batch_size\n",
    "        ]  # [batch_size * n_obs_history, latent_dim]\n",
    "        normalized_batch_samples = normalized_batch_samples.reshape(\n",
    "            (-1, normalized_batch_samples.shape[-1])\n",
    "        )\n",
    "\n",
    "        # Denormalize using the latents statistics.\n",
    "        # Range: [latent_min, latent_max]\n",
    "        batch_samples = denormalize_pn1(\n",
    "            normalized_batch_samples, latent_min, latent_max\n",
    "        )\n",
    "\n",
    "        # Decode using the VAE.\n",
    "        # [batch_size * n_obs_history, C, H, W]\n",
    "        # Range: [-1, 1]\n",
    "        decoded_batch = vae_model.decode(torch.from_numpy(batch_samples).to(device))\n",
    "        decoded_batch = decoded_batch.reshape(\n",
    "            reshape_batch_shape + list(decoded_batch.shape[1:])\n",
    "        )\n",
    "        # print(\"decoded_batch:\", decoded_batch.shape)\n",
    "        decoded_normalized_samples.append(decoded_batch.cpu().detach().numpy())\n",
    "\n",
    "    decoded_normalized_samples = np.concatenate(decoded_normalized_samples)\n",
    "\n",
    "    # Denormalize.\n",
    "    view_recons = decoded_normalized_samples.transpose(0, 1, 3, 4, 2)\n",
    "    # Range: [0, 1]\n",
    "    view_recons = (view_recons + 1) / 2\n",
    "    # Range: [0, 255]\n",
    "    view_recons *= 255\n",
    "    view_recons = view_recons.astype(np.uint8)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5821e4",
   "metadata": {},
   "source": [
    "batch_samples.min(), latent_min"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd398481",
   "metadata": {},
   "source": [
    "num_rollouts = 10\n",
    "fig, axs = plt.subplots(num_rollouts, n_obs_history, figsize=(24, 24), squeeze=False)\n",
    "for i in range(num_rollouts):\n",
    "    for j in range(n_obs_history):\n",
    "        ax = axs[i, j]\n",
    "        ax.imshow(view_recons[i, j])\n",
    "        ax.axis(\"off\")\n",
    "fig.tight_layout()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373453c9",
   "metadata": {},
   "source": [
    "# TODO: remove NaNs?\n",
    "for norm_samples_i in normalized_samples:\n",
    "    print(norm_samples_i.min(), norm_samples_i.max())\n",
    "# (\n",
    "#     normalized_samples[~np.isnan(normalized_samples)].min(),\n",
    "#     normalized_samples[~np.isnan(normalized_samples)].max(),\n",
    "# )"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b8b12a",
   "metadata": {},
   "source": [
    "# Fraction of samples in-range\n",
    "((normalized_samples >= -1) & (normalized_samples <= 1)).all(axis=(-2, -1)).sum(axis=-1) / num_samples"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fff0a54",
   "metadata": {},
   "source": [
    "in_range_normalized_samples = []\n",
    "for num_steps in range(normalized_samples.shape[0]):\n",
    "    mask = ((normalized_samples >= -1) & (normalized_samples <= 1)).all(axis=(-2, -1))\n",
    "    in_range_normalized_samples.append(normalized_samples[mask])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e874ce11",
   "metadata": {},
   "source": [
    "if obs_key == \"state\":\n",
    "    # [len(return_steps), num_in_range_samples, n_obs_history, dim=5]\n",
    "    in_range_samples = np.array(\n",
    "        [\n",
    "            denormalize_pn1(s, min_state, max_state)\n",
    "            for s in in_range_normalized_samples\n",
    "        ]\n",
    "    )"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9f0912",
   "metadata": {},
   "source": [
    "def plot_samples(samples=None, data=None, max_num_dims=None, save_dir=None):\n",
    "    if samples is None and data is None:\n",
    "        raise ValueError(\"Either samples or data must be provided.\")\n",
    "\n",
    "    # Plot histogram of each dimension of the samples\n",
    "    for i, steps in enumerate(return_steps):\n",
    "        if samples is not None:\n",
    "            step_samples = samples[i]  # [num_samples, n_history, dim]\n",
    "            n_history = step_samples.shape[1]\n",
    "            dim = step_samples.shape[2]\n",
    "        else:\n",
    "            n_history, dim = data.shape[1:]\n",
    "\n",
    "        dim = min(dim, max_num_dims)\n",
    "\n",
    "        fig, ax = plt.subplots(\n",
    "            n_history, dim, figsize=(dim * 3, n_history * 4), squeeze=False\n",
    "        )\n",
    "\n",
    "        for i in range(n_history):\n",
    "            for j in range(dim):\n",
    "                if samples is not None:\n",
    "                    ax[i, j].hist(\n",
    "                        step_samples[:, i, j],\n",
    "                        density=True,\n",
    "                        bins=50,\n",
    "                        color=\"blue\",\n",
    "                        alpha=0.5,\n",
    "                    )\n",
    "                if data is not None:\n",
    "                    ax[i, j].hist(\n",
    "                        data[:, i, j],\n",
    "                        density=True,\n",
    "                        bins=50,\n",
    "                        color=\"green\",\n",
    "                        alpha=0.5,\n",
    "                    )\n",
    "                ax[i, j].set_title(f\"History {i}, Dim {j}\")\n",
    "\n",
    "        fig.suptitle(f\"{steps} steps\")\n",
    "        if save_dir is not None:\n",
    "            plt.savefig(os.path.join(save_dir, f\"histogram_{steps}.png\"))\n",
    "        else:\n",
    "            plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4b6e1c",
   "metadata": {},
   "source": [
    "if obs_key == \"state\":\n",
    "    n_data, state_dim = dataset.replay_buffer[\"state\"].shape\n",
    "    plot_samples(\n",
    "        samples,\n",
    "        np.broadcast_to(\n",
    "            dataset.replay_buffer[\"state\"][:, None], [n_data, n_obs_history, state_dim]\n",
    "        ),\n",
    "        save_dir=None,\n",
    "    )\n",
    "elif obs_key == \"img\":\n",
    "    num_data = 10000\n",
    "    data = []\n",
    "    for norm_obs, _ in train_loader:\n",
    "        norm_obs = norm_obs[obs_key].detach().cpu().numpy()\n",
    "        obs = normalize_pn1(norm_obs, latent_min, latent_max)\n",
    "        data.append(obs)\n",
    "        if len(data) >= num_data:\n",
    "            break\n",
    "    data = np.concatenate(data)\n",
    "    plot_samples(\n",
    "        # samples=normalized_samples,\n",
    "        samples=in_range_normalized_samples,\n",
    "        data=data,\n",
    "        max_num_dims=4,\n",
    "        save_dir=None,\n",
    "    )"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e2a18a",
   "metadata": {},
   "source": [
    "diff_states = []\n",
    "for obs_history, pred_horizon in train_loader:\n",
    "    norm_state = obs_history[\"state\"].detach().cpu().numpy()  # [batch_size, n_history, dim]\n",
    "    state = denormalize_pn1(norm_state, min_state, max_state)  # [batch_size, n_history, dim]\n",
    "    diff_states.append(np.diff(state, axis=1))  # [batch_size, n_history - 1, dim]\n",
    "\n",
    "diff_states = np.concatenate(diff_states, axis=0)  # [n_samples, n_history - 1, dim]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be46082",
   "metadata": {},
   "source": [
    "diff_samples = np.diff(in_range_samples, axis=2)  # [len(return_steps), num_in_range_samples, n_history - 1, dim]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6817dbd",
   "metadata": {},
   "source": [
    "plot_samples(diff_samples, diff_states, save_dir=None)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af39a02",
   "metadata": {},
   "source": [
    "# Plot histogram of each dimension of the samples\n",
    "for i, steps in enumerate(return_steps):\n",
    "    step_diff_samples = diff_samples[i]  # [num_samples, n_history - 1, dim]\n",
    "    assert len(step_diff_samples.shape) == 3\n",
    "    n_history = step_diff_samples.shape[1]\n",
    "    dim = step_diff_samples.shape[2]\n",
    "\n",
    "    fig, axs = plt.subplots(n_history, dim, figsize=(12, 12))\n",
    "\n",
    "    for i in range(n_history):\n",
    "        for j in range(dim):\n",
    "            ax = axs[i, j]\n",
    "            # Samples\n",
    "            ax.hist(\n",
    "                step_diff_samples[:, i, j],\n",
    "                density=True,\n",
    "                bins=50,\n",
    "                color=\"blue\",\n",
    "                alpha=0.5,\n",
    "                # label=f\"samples {i}\",\n",
    "            )\n",
    "            # Real data\n",
    "            ax.hist(\n",
    "                diff_states[:, i, j],\n",
    "                density=True,\n",
    "                bins=50,\n",
    "                color=\"green\",\n",
    "                alpha=0.5,\n",
    "                # label=f\"replay {i}\",\n",
    "            )\n",
    "\n",
    "            ax.set_title(f\"History {i}, Dim {j}\")\n",
    "            # ax.legend()\n",
    "\n",
    "    fig.suptitle(f\"{steps} steps\")\n",
    "    plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d029b180",
   "metadata": {},
   "source": [
    "# Plot histogram of each dimension of the samples\n",
    "for i, steps in enumerate(return_steps):\n",
    "    fig, axs = plt.subplots(n_history, dim, figsize=(12, 12))\n",
    "\n",
    "    for i in range(n_history):\n",
    "        for j in range(dim):\n",
    "            ax = axs[i, j]\n",
    "            ax.hist(\n",
    "                diff_states[:, i, j],\n",
    "                density=True,\n",
    "                bins=50,\n",
    "                color=\"green\",\n",
    "                alpha=0.5,\n",
    "                # label=f\"replay {i}\",\n",
    "            )\n",
    "\n",
    "            # ax.set_title(f\"History {i}, Dim {j}\")\n",
    "            # ax.legend()\n",
    "\n",
    "    fig.suptitle(f\"{steps} steps\")\n",
    "    plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1401e80a",
   "metadata": {},
   "source": [
    "# Plot a few sampled and real trajectories.\n",
    "n_samples = 30\n",
    "obs_history, pred_horizon = next(iter(train_loader))\n",
    "norm_state = obs_history[\"state\"][:n_samples].cpu().numpy()  # [n_samples, n_history, dim]\n",
    "state = denormalize_pn1(norm_state, min_state, max_state)  # [n_samples, n_history, dim]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c323d0",
   "metadata": {},
   "source": [
    "# Plot a few sampled and real trajectories.\n",
    "n_samples = 30\n",
    "obs_history, pred_horizon = next(iter(train_loader))\n",
    "norm_state = obs_history[\"state\"][:n_samples].cpu().numpy()  # [n_samples, n_history, dim]\n",
    "state = denormalize_pn1(norm_state, min_state, max_state)  # [n_samples, n_history, dim]\n",
    "\n",
    "dim = state.shape[1]\n",
    "fig, axs = plt.subplots(dim, 2, figsize=(8, dim * 4))\n",
    "\n",
    "for i in range(dim):\n",
    "    real_ax = axs[i, 0]\n",
    "    real_i = state[:, :, i]\n",
    "    real_ax.plot(real_i.T, alpha=0.5, label=\"real\")\n",
    "    real_ax.set_title(f\"Real dim {i}\")\n",
    "\n",
    "    sample_ax = axs[i, 1]\n",
    "    samples_i = in_range_samples[0, :n_samples, :, i]\n",
    "    sample_ax.plot(samples_i.T, alpha=0.5, label=\"sample\")\n",
    "    sample_ax.set_title(f\"Samples dim {i}\")\n",
    "\n",
    "    # Set the same ylim for both axes.\n",
    "    # min_y = min(real_i.min(), samples_i.min())\n",
    "    # max_y = max(real_i.max(), samples_i.max())\n",
    "    min_y = min_state[i]\n",
    "    max_y = max_state[i]\n",
    "    real_ax.set_ylim(min_y, max_y)\n",
    "    sample_ax.set_ylim(min_y, max_y)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "961848fd",
   "metadata": {},
   "source": [
    "### Debug sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf88f6b",
   "metadata": {},
   "source": [
    "for p in diffusion.model.parameters():\n",
    "    # print(p)\n",
    "    if torch.isnan(p).any():\n",
    "        print(\"NaNs in the parameters.\")\n",
    "    else:\n",
    "        param_norm = p.norm(2)\n",
    "        print(param_norm)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
